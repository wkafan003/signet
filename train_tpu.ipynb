{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "train_tpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx3QHJG0kq4p"
      },
      "source": [
        "Аналогичный signet-keras процесс обучения, но вместо gpu используются тензорные процессоры, отправляя данные на сервер google, которые позволяют существенно сократить время обучения.\n",
        "К сожалению с ray, из-за проблем внутренней архитектуры, совместить не получилось."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO_ezkbbh0li"
      },
      "source": [
        "try:\n",
        "    import gdown\n",
        "    import natsort\n",
        "except:\n",
        "    !pip install natsort gdown"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb43g5cXh0lp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import keras\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "from keras import models\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, Input, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Lambda\n",
        "import natsort as ns\n",
        "import time\n",
        "from numba import cuda"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHYNQhaPh0lr"
      },
      "source": [
        "PATH_ORG = \"./signatures/full_org\"\n",
        "PATH_FORG = \"./signatures/full_forg\"\n",
        "checkpoints_path = \"./checkpoints\"\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYbYhWpsh0ls"
      },
      "source": [
        "\n",
        "\n",
        "if os.path.exists('signatures.zip') is False:\n",
        "    !gdown https://drive.google.com/uc?id=1PpPVry5TkfGVpbFDkwOMNx7Xew4vscW5\n",
        "#"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pTtM0knh0lu"
      },
      "source": [
        "if os.path.exists('signatures') is False:\n",
        "    !unzip -q -n signatures.zip"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgijIuWjh0lw"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, df, batch_size=32, dim=(155, 220), n_channels=3, shuffle=True, lazy=True):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.labels = df[\"label\"].to_numpy().astype(np.int32)\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.lazy = lazy\n",
        "        if self.lazy is False:\n",
        "            self.data = [np.empty((df.shape[0], *dim, n_channels), dtype=np.float32),\n",
        "                         np.empty((df.shape[0], *dim, n_channels), dtype=np.float32)]\n",
        "            for i in range(df.shape[0]):\n",
        "                image_1 = cv2.imread(df.iloc[i, 0])\n",
        "                image_1 = cv2.resize(image_1, (220, 155))\n",
        "                image_1 = 1-image_1/255.0\n",
        "\n",
        "                image_2 = cv2.imread(df.iloc[i, 1])\n",
        "                image_2 = cv2.resize(image_2, (220, 155))\n",
        "                image_2 = 1-image_2/255.0\n",
        "                self.data[0][i, :, :, :] = image_1\n",
        "                self.data[1][i, :, :, :] = image_2\n",
        "                # x_1[i,] = 1 - image_1 / 255.0\n",
        "                # x_2[i,] = 1 - image_2 / 255.0\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # return X, y\n",
        "        if self.lazy is False:\n",
        "            x = []\n",
        "            x.append(self.data[0][indexes, :, :, :])\n",
        "            x.append(self.data[1][indexes, :, :, :])\n",
        "\n",
        "            y = self.labels[indexes]\n",
        "\n",
        "        else:\n",
        "            rows = [self.df.iloc[k] for k in indexes]\n",
        "            x, y = self.__data_generation(rows)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.df.shape[0])\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, rows):\n",
        "        x_1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        x_2 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        for i in range(len(rows)):\n",
        "            image_1 = cv2.imread(rows[i][\"image_1\"])\n",
        "            image_1 = cv2.resize(image_1, (220, 155))\n",
        "            image_1 = np.array(image_1)\n",
        "            image_2 = cv2.imread(rows[i][\"image_2\"])\n",
        "            image_2 = cv2.resize(image_2, (220, 155))\n",
        "            image_2 = np.array(image_2)\n",
        "            x_1[i,] = 1 - image_1 / 255.0\n",
        "            x_2[i,] = 1 - image_2 / 255.0\n",
        "            y[i] = rows[i][\"label\"]\n",
        "\n",
        "        return [x_1, x_2], y\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZaTpYqfh0lz"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def euclidean_distance2(y):\n",
        "    return K.sqrt(K.sum(K.square(y[0] - y[1]), axis=-1))\n",
        "\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzlSL5W9h0l0"
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    sqaure_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    y_true = K.cast(y_true, y_pred.dtype)\n",
        "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGwjSUbYh0l1"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_net():\n",
        "    input = Input(shape=(155, 220, 3))\n",
        "\n",
        "    conv_1 = Conv2D(filters=96, kernel_size=(11, 11))(input)\n",
        "    batch_norm_1 = BatchNormalization()(conv_1)\n",
        "    activation_1 = Activation('relu')(batch_norm_1)\n",
        "    max_pool_1 = MaxPooling2D(pool_size=(3, 3))(activation_1)\n",
        "\n",
        "    conv_2 = Conv2D(filters=256, kernel_size=(5, 5))(max_pool_1)\n",
        "    batch_norm_2 = BatchNormalization()(conv_2)\n",
        "    activation_2 = Activation('relu')(batch_norm_2)\n",
        "    max_pool_2 = MaxPooling2D(pool_size=(3, 3))(activation_1)\n",
        "\n",
        "    dropout_1 = Dropout(rate=0.3)(max_pool_2)\n",
        "\n",
        "    conv_3_a = Conv2D(filters=384, kernel_size=(3, 3))(dropout_1)\n",
        "    activation_3_a = Activation('relu')(conv_3_a)\n",
        "    conv_3_b = Conv2D(filters=256, kernel_size=(3, 3))(activation_3_a)\n",
        "    activation_3_b = Activation('relu')(conv_3_b)\n",
        "    max_pool_3 = MaxPooling2D(pool_size=(3, 3))(activation_3_b)\n",
        "\n",
        "    # dropout_22 = Dropout(rate=0.3)(max_pool_3)\n",
        "    # conv_4_a = Conv2D(filters=384, kernel_size=(3, 3))(dropout_22)\n",
        "    # activation_4_a = Activation('relu')(conv_4_a)\n",
        "    # conv_4_b = Conv2D(filters=512, kernel_size=(3, 3))(activation_4_a)\n",
        "    # activation_4_b = Activation('relu')(conv_4_b)\n",
        "    # max_pool_4 = MaxPooling2D(pool_size=(2, 2))(activation_4_b)\n",
        "\n",
        "    dropout_2 = Dropout(rate=0.3)(max_pool_3)\n",
        "    # dropout_2 = Dropout(rate=0.3)(max_pool_3)\n",
        "\n",
        "    flat_1 = Flatten()(dropout_2)\n",
        "    fc_1 = Dense(units=1024, activation='relu')(flat_1)\n",
        "    dropout_3 = Dropout(rate=0.5)(fc_1)\n",
        "    fc_2 = Dense(units=128, activation='relu')(dropout_3)\n",
        "\n",
        "\n",
        "\n",
        "    input_a = Input(shape=(155, 220, 3))\n",
        "    input_b = Input(shape=(155, 220, 3))\n",
        "\n",
        "    base_net = Model(input, fc_2)\n",
        "    processed_a = base_net(input_a)\n",
        "    processed_b = base_net(input_b)\n",
        "\n",
        "    distance = Lambda(euclidean_distance2)([processed_a, processed_b])\n",
        "    # distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "    model = Model([input_a, input_b], distance)\n",
        "    return base_net,model\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2laJldJ8h0l2"
      },
      "source": [
        "params = {\n",
        "    'dim': (155, 220),\n",
        "    'batch_size': 16,\n",
        "    # 'batch_size': 64,\n",
        "    'n_channels': 3,\n",
        "    'shuffle': False\n",
        "}\n",
        "\n",
        "\n",
        "def get_data(path_org, path_forg, test_size=0.3, random_state=0, lazy=True, ext_data=0):\n",
        "    org = ns.natsorted(os.listdir(path_org), alg=ns.IGNORECASE)\n",
        "    forg = ns.natsorted(os.listdir(path_forg), alg=ns.IGNORECASE)\n",
        "    org = [os.path.join(PATH_ORG, i) for i in org if i.endswith('.png')]\n",
        "    forg = [os.path.join(PATH_FORG, i) for i in forg if i.endswith('.png')]\n",
        "\n",
        "    org = [os.path.abspath(i) for i in org]\n",
        "    forg = [os.path.abspath(i) for i in forg]\n",
        "\n",
        "    samples = 24\n",
        "    ppl = len(org) // samples\n",
        "\n",
        "    data = []\n",
        "    for i in range(ppl):\n",
        "        tr = np.array([[org[j], org[j], 1] for j in range(i * samples, (i + 1) * samples)])\n",
        "        tr[:, 1] = np.concatenate([tr[:-12, 1], tr[-12:, 1]])\n",
        "        tr[:, 1] = np.random.permutation(tr[:, 1])\n",
        "        fl = np.array([[org[j], forg[j], 0] for j in range(i * samples, (i + 1) * samples)])\n",
        "\n",
        "        for j in range(ext_data):\n",
        "            rand2 = np.random.choice(\n",
        "                np.concatenate([np.arange(0, i * samples), np.arange((i + 1) * samples, ppl * samples)]),\n",
        "                samples, replace=False)\n",
        "            tr2 = np.array([[org[j], org[rand2[j % samples]], 0] for j in range(i * samples, (i + 1) * samples)])\n",
        "            data.append(tr2)\n",
        "\n",
        "        data.append(tr)\n",
        "        data.append(fl)\n",
        "\n",
        "    df = pd.DataFrame(np.array(data).reshape(-1, 3), columns=[\"image_1\", \"image_2\", \"label\"])\n",
        "    df = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "    ds_train, ds_val = train_test_split(df, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    train_datagen = DataGenerator(ds_train, **params, lazy=lazy)\n",
        "    validation_datagen = DataGenerator(ds_val, **params, lazy=lazy)\n",
        "    return train_datagen, validation_datagen"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbCZEuu1h0l5",
        "outputId": "b2f75da7-c8f2-40ca-c770-36d2987a6796"
      },
      "source": [
        "\n",
        "# #!!!!!!!!!!!!!!!!!\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.89.196.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.89.196.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.196.146:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.196.146:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrcH--DHh0l7"
      },
      "source": [
        "train_datagen, validation_datagen = get_data(PATH_ORG, PATH_FORG,\n",
        "                                             test_size=0.3, random_state=0, lazy=False, ext_data=0)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRF0MzOXh0mK"
      },
      "source": [
        "with strategy.scope():\n",
        "    base_net,model = make_net()\n",
        "    optimizer = optimizers.Adam(learning_rate=0.0005)\n",
        "    model.compile(loss=contrastive_loss,optimizer=optimizer, metrics=[accuracy])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l17hrTvlh0mK",
        "outputId": "1f9afd01-6777-413d-f970-55dbe66de9e8"
      },
      "source": [
        "x1 = (train_datagen.data[0], train_datagen.data[1])\n",
        "y1 = train_datagen.labels\n",
        "#\n",
        "x2 = (validation_datagen.data[0], validation_datagen.data[1])\n",
        "y2 = validation_datagen.labels\n",
        "\n",
        "model.fit(x1,y1,batch_size=128, validation_data=(x2,y2), epochs=20, callbacks=None)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 73s 4s/step - loss: 15.8155 - accuracy: 0.5816 - val_loss: 0.4912 - val_accuracy: 0.5320\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 3s 200ms/step - loss: 0.1706 - accuracy: 0.7641 - val_loss: 0.4912 - val_accuracy: 0.5320\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 3s 199ms/step - loss: 0.1395 - accuracy: 0.8099 - val_loss: 0.4901 - val_accuracy: 0.5320\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.1470 - accuracy: 0.8086 - val_loss: 0.4911 - val_accuracy: 0.5320\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.1356 - accuracy: 0.8266 - val_loss: 0.4911 - val_accuracy: 0.5320\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.1226 - accuracy: 0.8444 - val_loss: 0.4782 - val_accuracy: 0.5320\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 3s 196ms/step - loss: 0.1043 - accuracy: 0.8607 - val_loss: 0.4676 - val_accuracy: 0.5320\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0915 - accuracy: 0.8908 - val_loss: 0.4241 - val_accuracy: 0.5320\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0817 - accuracy: 0.9048 - val_loss: 0.4167 - val_accuracy: 0.5320\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 3s 196ms/step - loss: 0.0742 - accuracy: 0.9157 - val_loss: 0.3532 - val_accuracy: 0.5320\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0728 - accuracy: 0.9139 - val_loss: 0.2694 - val_accuracy: 0.5320\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0643 - accuracy: 0.9312 - val_loss: 0.2637 - val_accuracy: 0.5320\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0598 - accuracy: 0.9387 - val_loss: 0.2980 - val_accuracy: 0.5320\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0586 - accuracy: 0.9361 - val_loss: 0.2433 - val_accuracy: 0.5409\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 3s 192ms/step - loss: 0.0694 - accuracy: 0.9255 - val_loss: 0.1174 - val_accuracy: 0.7958\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0637 - accuracy: 0.9317 - val_loss: 0.1011 - val_accuracy: 0.8616\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0496 - accuracy: 0.9472 - val_loss: 0.0651 - val_accuracy: 0.9394\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0463 - accuracy: 0.9462 - val_loss: 0.0549 - val_accuracy: 0.9438\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 3s 190ms/step - loss: 0.0360 - accuracy: 0.9608 - val_loss: 0.0057 - val_accuracy: 0.9989\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0466 - accuracy: 0.9445 - val_loss: 0.0349 - val_accuracy: 0.9721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1348065b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJwmclnPh0mL",
        "outputId": "0a01901b-1062-4c68-8816-9747d7b5a549"
      },
      "source": [
        "model.fit(x1,y1,batch_size=128, validation_data=(x2,y2), epochs=20, callbacks=None)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 10s 676ms/step - loss: 0.0317 - accuracy: 0.9662 - val_loss: 0.0138 - val_accuracy: 0.9866\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0305 - accuracy: 0.9641 - val_loss: 0.0052 - val_accuracy: 0.9978\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.0321 - accuracy: 0.9733 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0416 - accuracy: 0.9521 - val_loss: 0.0068 - val_accuracy: 0.9911\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0295 - accuracy: 0.9627 - val_loss: 0.0350 - val_accuracy: 0.9632\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0291 - accuracy: 0.9711 - val_loss: 0.0048 - val_accuracy: 0.9955\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0250 - accuracy: 0.9734 - val_loss: 0.0115 - val_accuracy: 0.9866\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.0254 - accuracy: 0.9716 - val_loss: 0.0066 - val_accuracy: 0.9933\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 3s 196ms/step - loss: 0.0246 - accuracy: 0.9674 - val_loss: 2.3468e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.0270 - accuracy: 0.9756 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0201 - accuracy: 0.9772 - val_loss: 0.0019 - val_accuracy: 0.9989\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.0218 - accuracy: 0.9785 - val_loss: 6.0522e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.0205 - accuracy: 0.9763 - val_loss: 0.0012 - val_accuracy: 0.9989\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.0212 - accuracy: 0.9734 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0198 - accuracy: 0.9753 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0167 - accuracy: 0.9806 - val_loss: 9.7091e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 3s 192ms/step - loss: 0.0191 - accuracy: 0.9799 - val_loss: 6.2963e-04 - val_accuracy: 0.9989\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 3s 190ms/step - loss: 0.0301 - accuracy: 0.9650 - val_loss: 0.0102 - val_accuracy: 0.9866\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.0238 - accuracy: 0.9737 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 3s 192ms/step - loss: 0.0187 - accuracy: 0.9785 - val_loss: 1.6697e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f134dc077d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP7uT1Qlu40Q"
      },
      "source": [
        "Средневзвешенная точность тестовой и оубчающейся выборок "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nru5Nkv_h0mM"
      },
      "source": [
        "a1=accuracy(y2,model.predict(x2))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWO1F2ebh0mN"
      },
      "source": [
        "a2=accuracy(y1,model.predict(x1))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7oFmEJlh0mN",
        "outputId": "94642079-29e4-4c6a-8094-4995a7c4bab3"
      },
      "source": [
        "(a1*len(y1)+a2*len(y2))/(len(y1)+len(y2))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phXGpNRah0mO"
      },
      "source": [
        "model_dir = \"./checkpoints/best\"\n",
        "\n",
        "localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
        "model.save_weights(model_dir, options=localhost_save_option)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8q5AxMsh0mO",
        "outputId": "b9b636f6-5c3b-42c2-d442-8bfa07899fa6"
      },
      "source": [
        "!zip -r weights.zip ./checkpoints"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: checkpoints/ (stored 0%)\n",
            "updating: checkpoints/best.index (deflated 68%)\n",
            "updating: checkpoints/best.data-00000-of-00001 (deflated 7%)\n",
            "updating: checkpoints/checkpoint (deflated 35%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}